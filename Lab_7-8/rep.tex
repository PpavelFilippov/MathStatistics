\section{Постановка задачи}
    \begin{enumerate}
        \item 
        \item 
    \end{enumerate}

\section{Теория}    
    \subsection{Проверка гипотезы о законе распределения генеральной совокупности. Метод хи-квадрат}
    Исчерпывающей характеристикой изучаемой случайной величины является её закон распределения. Поэтому естественно стремление исследователей построить этот закон приближённо на основе статистических данных.\\ \\
    Сначала выдвигается гипотеза о виде закона распределения.\\ \\
    После того как выбран вид закона, возникает задача оценивания
его параметров и проверки (тестирования) закона в целом. \\ \\
Для проверки гипотезы о законе распределения применяются критерии согласия. Таких критериев существует много. Мы рассмотрим
наиболее обоснованный и наиболее часто используемый в практике
— критерий $\chi^2$ (хи-квадрат), введённый К.Пирсоном (1900 г.) для
случая, когда параметры распределения известны. Этот критерий
был существенно уточнён Р.Фишером (1924 г.), когда параметры
распределения оцениваются по выборке, используемой для проверки.\\ \\
Мы ограничимся рассмотрением случая одномерного распределе2
ния. \\ \\
Итак, выдвинута гипотеза $H_{0}$ о генеральном законе распределения
с функцией распределения $F(x)$ \\ \\
Рассматриваем случай, когда гипотетическая функция распределения $F(x)$ не содержит неизвестных параметров.\\ \\
Разобьём генеральную совокупность, т.е. множество значений изучаемой случайной величины $X$ на $k$ непересекающихся подмножеств $\Delta_1,\Delta_2,\dots, \Delta_{k}.$\\ \\
Пусть $p_{i} = P(X \in \Delta_{i}), i = 1,\dots,k$ \\ \\
Если генеральная совокупность — вся вещественная ось,
то подмножества $\Delta_{i} = (a_{i-1}, a_i]$ — полуоткрытые промежутки ($i = 2,\dots,k-1$). Крайние промежутки будут полубесконечными: $\Delta_1 = (-\infty, a_1]$, 
$\Delta_{k} = (a_{k-1}, +\infty)$. В этом случае $p_{i} = F(a_i) - F(a_{i-1}); a_0 = -\infty, a_{k} = +\infty$($i = 1, \dots, k$) \\ \\
Отметим, что $\sum_{i=1}^{k}p_i = 1$. Будем предполагать, что все $p_i > 0$($i = 1, \dots, k$)\\ \\
Пусть, далее, $n_1, n_2, \dots, n_k$ — частоты попадания выборочных
элементов в подмножества  $\Delta_1,\Delta_2,\dots, \Delta_{k}.$ соответственно. \\ \\
В случае справедливости гипотезы $H_{0}$ относительные частоты $\frac{n_i}{n}$
при большом $n$ должны быть близки к вероятностям $p_i$($i = 1, \dots, k$),
поэтому за меру отклонения выборочного распределения от гипотетического с функцией $F(x)$  естественно выбрать величину
\begin{gather}
    Z = \sum_{i=1}^{k}{c_i(\frac{n_i}{n}-p_i)^2}
\end{gather}
где $c_i$ — какие-нибудь положительные числа (веса). К.Пирсоном в
качестве весов выбраны числа $c_i = \frac{n}{p_i}$ ($i = 1, \dots, k$). Тогда получается
статистика критерия хи-квадрат К.Пирсона
\begin{gather}
    \chi^2 = \sum_{i=1}^{k}{\frac{n}{p_i}(\frac{n_i}{n}-p_i)^2} = \sum_{i=1}^{k}{\frac{(n_i-np_i)^2}{np_i}}
\end{gather}
которая обозначена тем же символом, что и закон распределения
хи-квадрат.\\ \\ 
К.Пирсоном доказана теорема об асимптотическом поведении
статистики $\chi^2$, указывающая путь её применения.\\ \\ 
\textbf{Теорема К.Пирсона} Статистика критерия $\chi^2$ асимптотически распределена по закону $\chi^2$ с $k-1$ степенями свободы.\\ \\ 
Это означает, что независимо от вида проверяемого распределения, т.е. функции $F(x)$, выборочная функция распределения статистики $\chi^2$ при $n \longrightarrow \infty$ стремится к функции распределения случайной величины
с плотностью вероятности
\begin{gather}
    f_{k-1}(x) =
    \begin{cases}
        0, x \leq 0\\
        \frac{1}{2^{\frac{k-1}{2}}\Gamma \left(  \frac{k-1}{2}\right)}{x}^{\frac{k-3}{2}}{e}^{\frac{x}{2}},  x > 0 \\ 
    \end{cases}
\end{gather}
Для прояснения сущности метода $\chi^2$ сделаем ряд замечаний. \\ \\ 
\textbf{Замечание 1} Выбор подмножеств $\Delta_1,\Delta_2,\dots, \Delta_{k}.$ и их числа $k$ в
принципе ничем не регламентируется, так как $n \longrightarrow \infty$. Но так как число
$n$ хотя и очень большое, но конечное, то $k$ должно быть с ним согласовано. Обычно его берут таким же, как и для построения гистограммы,
т.е. можно руководствоваться формулой
\begin{gather}
    k \approx 1.72\sqrt[3]{n}
\end{gather}
или формулой Старджесса
\begin{gather}
    k \approx 1 + 3.3lg(n)
\end{gather}
При этом, если $\Delta_1,\Delta_2,\dots, \Delta_{k}.$ — промежутки, то их длины удобно
сделать равными, за исключением крайних — полубесконечных. \\ \\
\textbf{Замечание 2} (о числе степеней свободы).
Числом степеней свободы функции (по старой терминологии)
называется число её независимых аргументов. Аргументами статистики $\chi^2$ являются частоты $n_1, n_2, \dots, n_k$. Эти частоты связаны
одним равенством $n_1 + n_2 + \dots + n_k = n$, а в остальном
независимы в силу независимости элементов выборки. Таким образом,
функция $\chi^2$ имеет $k-1$ независимых аргументов: число частот
минус одна связь. В силу теоремы Пирсона число степеней свободы
статистики $\chi^2$ отражается на виде асимптотической плотности $f_{k-1}(x)$.\\ \\ 
На основе общей схемы проверки статистических гипотез сформулируем следующее правило.\\ \\
\textbf{ Правило проверки гипотезы о законе распределения по методу $\chi^2$}
\begin{enumerate}
    \item Выбираем уровень значимости $\alpha$
    \item Находим квантиль ${\chi_{1-\alpha}}^2(k-1)$ распределения
хи-квадрат с $k-1$ степенями свободы порядка $1-\alpha$. 
    \item С помощью гипотетической функции распределения $F(x)$ вычисляем вероятности $p_{i} = P(X \in \Delta_{i}), i = 1,\dots,k$.
    \item Вычисляем выборочное значение статистики критерия $\chi^2$:
    \begin{gather}
        {\chi_{B}}^2 = \sum_{i=1}^{k}\frac{(n_i - np_i)^2}{np_i}
    \end{gather}
    \item Сравниваем $ {\chi_{B}}^2$ и квантиль ${\chi_{1-\alpha}}^2(k-1)$
    \begin{enumerate}
        \item  Если ${\chi_{B}}^2$ < ${\chi_{1-\alpha}}^2(k-1)$, то гипотеза $H_0$ на данном этапе проверки принимается.
        \item Если ${\chi_{B}}^2$ $\geq$ ${\chi_{1-\alpha}}^2(k-1)$, то гипотеза $H_0$ отвергается, выбирается одно из альтернативных распределений, и процедура
проверки повторяется.
    \end{enumerate}
\end{enumerate}
\textbf{Замечание 3}. Веса $c_i$ = \frac{n}{p_i}
пропорциональны $n$, т.е. с ростом $n$ увеличиваются. Отсюда следует,
что если выдвинутая гипотеза неверна, то относительные частоты
$\frac{n}{p_i}$ не будут близки к вероятностям $p_i$, и с ростом $n$ величина ${\chi_{B}}^2$ будет увеличиваться. При фиксированном уровне значимости
$\alpha$ будет фиксировано пороговое число — квантиль ${\chi_{1-\alpha}}^2(k-1)$,
поэтому, увеличивая $n$, мы придём к неравенству ${\chi_{B}}^2$ > ${\chi_{1-\alpha}}^2(k-1)$,
т.е. с увеличением объёма выборки неверная гипотеза будет отвергнута. \\ \\
Отсюда следует, что при сомнительной ситуации, когда ${\chi_{B}}^2$ \approx ${\chi_{1-\alpha}}^2(k-1)$, можно попытаться увеличить объём выборки(например, в 2 раза), чтобы требуемое неравенство было более чётким \\ \\
\textbf{Замечание 4}. Теория и практика применения критерия $\chi^2$ указывают, что если для каких-либо подмножеств $\Delta_{i}, i = 1,\dots,k$ условие
$np_i$ ≥ 5 не выполняется, то следует объединить соседние подмножества (промежутки).\\ \\
Это условие выдвигается требованием близости величин
\begin{gather}
    \frac{n_i - np_i}{sqrt{np_i}}
\end{gather}
квадраты которых являются слагаемыми $\chi^2$ к нормальным $N(0,1)$.
Тогда случайная величина будет распределена по закону, близкому к хи-квадрат. Такая близость обеспечивается достаточной
численностью элементов в подмножествах $\Delta_{i}$

    \subsection{Проверка гипотезы однородности выборки}

    Если выборка близка к нормальной, можно проверить, насколько
она однородна.
    \subsubsection{}

    F-тест или критерий Фишера (F-критерий, $\phi^{*}$-критерий) — статистический критерий, тестовая статистика которого при выполнении нулевой гипотезы имеет распределение Фишера (F-распределение).
В общм случае сравниваются две выборки A и B и проверяется
равенство их дисперсий:
\begin{gather}
    F = \frac{{\varsigma_{A}}^2}{{\varsigma_{D}}^2}
\end{gather}
Нулевая гипотеза $H_0$: ${\varsigma_{A}}^2 = {\varsigma_{B}}^2$\\
Статистика теста так или иначе сводится к отношению выборочных
дисперсий (сумм квадратов, деленных на «степени свободы»). Чтобы статистика имела распределение Фишера, необходимо, чтобы числитель и знаменатель были независимыми случайными величинами и соответствующие суммы квадратов имели распределение $\chi^2$. Для этого требуется, чтобы данные имели нормальное распределение. \\ \\
Статистика критерия Фишера (1.6) имеет распределение Фишера с $n-1$ и $m-1$ степенями свободы $F(n-1,m-1)$. Обычно в числителе ставится большая из двух сравниваемых дисперсий. \\ \\ 
Применим тест Фишера для выяснения однородности конкретной выборки. Для этого дисперсию выборки можно оценить двумя способами.\\
Во-первых, дисперсия, вычисленная для каждой группы — это оценка дисперсии совокупности. Поэтому дисперсию совокупности можно оценить на основании групповых дисперсий. Такая оценка не будет зависеть от различий групповых средних.\\
Во-вторых, разброс выборочных средних тоже позволяет оценить дисперсию совокупности. Понятно, что такая оценка дисперсии зависит от различий выборочных средних.\\
В качестве оценки дисперсии совокупности возьмем среднее выборочных дисперсий. Эта оценка называется внутригрупповой дисперсией. Обозначим ее ${s_{in}}^2$
\begin{gather}
    {s_{in}}^2 = \frac{1}{k}\sum_{i = 1}^{k}s_{i}^2 =  \frac{1}{k}\sum_{i=1}^{k}\frac{\sum_{j=1}^{n}(x_{ij}-\hat{X})^2}{k-1}
\end{gather}
где $\hat{X}$ — среднее для части выборки, $k$ — количество частей, на которое делим сходную выборку, $n$ — количество элементов в подвыборке.\\ \\ 
Также нужно вычислить межгрупповую дисперсию. Обозначается
она $s_{out}^2$.\\ \\ 
Вычисление межгрупповой дисперсии происходит в несколько этапов:
\begin{enumerate}
    \item Вычисление среднего значения для всех выбранных подвыборок $\left( \overline{X_1}, \dots, \overline{X_k} \right)$
    \item Вычисление среднего этих средних: $\overline{X} = \frac{1}{k}\sum_{i=1}^{k}\overline{X_i}$
    \item Вычисление межгрупповой дисперсии:
    \begin{gather}
        s_{out}^2 = k\cdot \frac{\sum_{j=1}^{n}(\overline{X_i} - \overline{X})^2}{k-1}
    \end{gather}
    Окончательно имеем для проверки гипотезы
    \begin{gather}
        F = \frac{s_{out}^2}{s_{in}^2}
    \end{gather}
    Если значение $F = \frac{s_{out}^2}{s_{in}^2} \approx 1$, выборку можно считать однородной
\end{enumerate}


    \subsubsection{}
    Данное правило используется для определения оптимального количества интервалов, на которые разбивается наблюдаемый диапазон изменения случайной величины при изучении ее распределения. По этому правилу число интервалов считается по формуле: 
    \begin{gather}
        n = 1 = log_{2}N
    \end{gather}
где $n$ — число интервалов, $N$ — общее число наблюдений.


\section{Результаты}
    